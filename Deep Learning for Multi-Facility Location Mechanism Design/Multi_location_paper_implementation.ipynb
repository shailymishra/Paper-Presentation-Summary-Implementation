{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi location paper implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT7gal9T23SH",
        "colab_type": "code",
        "outputId": "d4ed3b3e-82c7-4dc3-a178-17d17a91cad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "## Imports\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from torch import nn, optim\n",
        "\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko_T9O6v3BH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_agents = 5\n",
        "n_samples = 3000\n",
        "n_train_samples =1500\n",
        "use_cuda = torch.cuda.is_available()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R_xsgG83U4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Data Representation of Moulin net\n",
        "### Example of a data samples\n",
        "#### tensor([ 1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.2848,  \n",
        "####          1.0000, -1.0000, 1.0000, -1.0000, -1.0000,  0.3309,  \n",
        "#####         1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  0.6133,  \n",
        "#####         1.0000,  1.0000,  1.0000, -1.0000,  1.0000,  0.6381, \n",
        "####          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  0.8180])\n",
        "\n",
        "peaks = []\n",
        "for i in range(n_agents):\n",
        "  peak = np.random.rand(n_samples)\n",
        "  peaks.append(peak)\n",
        "peaks = np.array(peaks)\n",
        "\n",
        "def getbinaryrepresentation(array):\n",
        "  representation = np.full((n_agents), -1)\n",
        "  for value in array:\n",
        "    representation[value] = 1\n",
        "  return representation\n",
        "\n",
        "def generateDataSamples(peaks):\n",
        "  samples = []\n",
        "  for i in range(n_samples):\n",
        "    datasample = []\n",
        "    currentpeaks = peaks[:,i]\n",
        "    currentorder = np.argsort(currentpeaks)\n",
        "    sortedorder = currentpeaks[currentorder]\n",
        "    for j in range(n_agents):\n",
        "      representation = getbinaryrepresentation(currentorder[:j+1])\n",
        "      datasample.extend(representation)\n",
        "      datasample.append(sortedorder[j])\n",
        "    samples.append(datasample)\n",
        "  return torch.FloatTensor(samples)\n",
        "\n",
        "\n",
        "moulin_net_data = generateDataSamples(peaks)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z_eN8Hi4wa2",
        "colab_type": "code",
        "outputId": "ee873f76-d67c-4e15-a7ca-3e5355ffaecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Moulin net data - split in train and test\n",
        "indices = np.random.permutation(moulin_net_data.shape[0])\n",
        "training_idx, test_idx = indices[:n_train_samples], indices[n_train_samples:]\n",
        "moulin_train_data, moulin_test_data = moulin_net_data[training_idx,:], moulin_net_data[test_idx,:]\n",
        "print('moulin training shape', moulin_train_data.shape)\n",
        "print('moulin testing shape', moulin_test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "moulin training shape torch.Size([1500, 30])\n",
            "moulin testing shape torch.Size([1500, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oalymd-e3l7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Data Representation of Regret net\n",
        "## Example of data sample for regret net\n",
        "## tensor([0.1636, 0.6789, 0.8631, 0.2081, 0.8195])\n",
        "\n",
        "peaks = np.array([])\n",
        "for i in range(n_agents):\n",
        "  peak = np.random.rand(n_samples)\n",
        "  if(len(peaks) == 0):\n",
        "    peaks = peak\n",
        "  else:\n",
        "    peaks =  np.dstack((peaks,peak))\n",
        "\n",
        "peaks = np.reshape(peaks, (n_samples, n_agents ))\n",
        "regret_net_data = torch.FloatTensor(peaks)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp4WRIAN4gqT",
        "colab_type": "code",
        "outputId": "f4174cd4-f2f5-4e97-9430-e20e4363b90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Regret net data - split in train and test\n",
        "indices = np.random.permutation(regret_net_data.shape[0])\n",
        "training_idx, test_idx = indices[:n_train_samples], indices[n_train_samples:]\n",
        "regretnet_train_data, regretnet_test_data = regret_net_data[training_idx,:], regret_net_data[test_idx,:]\n",
        "print('regret training shape', regretnet_train_data.shape)\n",
        "print('regret testing shape', regretnet_test_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "regret training shape torch.Size([1500, 5])\n",
            "regret testing shape torch.Size([1500, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWmIP-PU5OJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MoulinNet(nn.Module):\n",
        "    def __init__(self, n_agents, K):\n",
        "        super(MoulinNet, self).__init__()\n",
        "        self.n_agents = n_agents\n",
        "        self.K = K\n",
        "        self.L = 3\n",
        "        self.J = 3\n",
        "        self.datasamplelength = (n_agents+1)*n_agents\n",
        "        ## if there are K facility, replicate the network K times\n",
        "        self.asNN = nn.ModuleList([ nn.Linear(self.n_agents,self.L*self.J)   for i in range(K)])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ## Outputvalues will contain the location of all K facilities for each data samples\n",
        "        outputvalues = torch.tensor([])\n",
        "        for k in range(self.K):\n",
        "          X_clone = x.clone()\n",
        "\n",
        "          ## Passing through a_s  neural network \n",
        "          ## from s get the a_s value\n",
        "          ## looping for each s value i.e. where number of s values are equal to no of agents\n",
        "          for i in range(0, self.datasamplelength  ,  self.n_agents+1  ):\n",
        "            ## layer 1 :  Pass through NN \n",
        "            tempvalue = self.asNN[k](X_clone[:,i:i+self.n_agents].clone())\n",
        "            ## layer 2 : get maximum \n",
        "            for j in range(0, self.L*self.J,self.J):\n",
        "              maxvalue_as, indicies = tempvalue[:,j:j+self.J].max(axis=1)\n",
        "              maxvalue_as = maxvalue_as.unsqueeze_(-1)\n",
        "              tempvalue[:,j:j+self.J] = maxvalue_as.clone()   \n",
        "            ## layer 3 : get minimum\n",
        "            minvalue_as, indicies = tempvalue.min(axis=1)\n",
        "            minvalue_as = minvalue_as.unsqueeze_(-1)\n",
        "\n",
        "            ### replacing the X_clone value with the minvalue obtained for s\n",
        "            ### Before : \n",
        "            X_clone[:,i:i+self.n_agents] = minvalue_as.clone()\n",
        "            ### After : \n",
        "\n",
        "          ## overall X_clone[0] will look like \n",
        "\n",
        "\n",
        "          ## Take maximum of a_s and peak\n",
        "          for i in range(0, (self.n_agents+1)*self.n_agents  ,  self.n_agents+1  ):\n",
        "            maxvalue, indicies = X_clone[:,i:i+self.n_agents+1].max(axis=1)\n",
        "            maxvalue = maxvalue.unsqueeze_(-1)\n",
        "            X_clone[:,i:i+self.n_agents+1] = maxvalue.clone()\n",
        "\n",
        "          ## from all that is left, take min and that is the location we obtain\n",
        "          minvalue, indicies = X_clone.min(axis=1)\n",
        "          minvalue = minvalue.unsqueeze_(-1)\n",
        "\n",
        "          ## for each K, append it to outputvalues\n",
        "          outputvalues  = torch.cat([outputvalues, minvalue.clone()], axis=1)\n",
        "        return outputvalues\n",
        "\n",
        "    def loss_function(self, y, x):\n",
        "      loss = torch.tensor([])\n",
        "      ## For each facility\n",
        "      for k in range(self.K):\n",
        "        ## fetch localtion for kth facility for all data points      \n",
        "        location_of_k_facility = y[:,k:k+1]\n",
        "        ## calculate loss i.e. peak - location\n",
        "        ### for now we are using x as whole to substract, later we will make all entries 0 expect the peak ones\n",
        "        appendloss = torch.add(x,-location_of_k_facility)    \n",
        "        ### append to loss for each facility\n",
        "        loss  = torch.cat([loss,appendloss ], axis = 1)\n",
        "\n",
        "      loss = torch.abs(loss)\n",
        "      loss = torch.reshape(loss, (x.shape[0],self.K,self.datasamplelength) )\n",
        "\n",
        "      ## for each each agent, we choose the minimum loss , i.e. loss corresponding to the location closest to its peak\n",
        "      loss , indices = torch.min(loss, axis=1)\n",
        "\n",
        "      ## all the entries expected peaks => 0      \n",
        "      for i in range(0,(self.n_agents+1)*self.n_agents, self.n_agents+1 ):\n",
        "        loss[:,i : i+self.n_agents] = 0  \n",
        "      \n",
        "      ## loss will be mean over all data sample, and for each data sample , mean over n_agents\n",
        "      loss = torch.mean((torch.sum(  loss , dim=1))/self.n_agents)\n",
        "      return loss\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQmhL2R_9J66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 26 May 20\n",
        "## multi facility\n",
        "class RegretNet(nn.Module):\n",
        "    def __init__(self, n_agents,K):\n",
        "        super(RegretNet, self).__init__()\n",
        "        self.n_agents = n_agents\n",
        "        self.unitperlayer = 40\n",
        "        self.K = K\n",
        "        self.M = 5  ## no of betas to calculate misreported peaks\n",
        "        self.fc1 = nn.Linear(self.n_agents,self.unitperlayer)\n",
        "        self.fc2 = nn.Linear(self.unitperlayer,self.unitperlayer)\n",
        "        self.fc3 = nn.Linear(self.unitperlayer,self.unitperlayer)\n",
        "        self.fc4 = nn.Linear(self.unitperlayer,self.unitperlayer)\n",
        "        self.fc5 = nn.Linear(self.unitperlayer,self.K)\n",
        "        torch.nn.init.uniform_(self.fc1.weight, a=0.0, b=0.01)\n",
        "        self.fc1.bias.data.fill_(0.1)\n",
        "        torch.nn.init.uniform_(self.fc2.weight, a=0.0, b=0.01)\n",
        "        self.fc2.bias.data.fill_(0.1)\n",
        "        torch.nn.init.uniform_(self.fc3.weight, a=0.0, b=0.01)\n",
        "        self.fc3.bias.data.fill_(0.1)\n",
        "        torch.nn.init.uniform_(self.fc4.weight, a=0.0, b=0.01)\n",
        "        self.fc4.bias.data.fill_(0.1)\n",
        "        torch.nn.init.uniform_(self.fc5.weight, a=0.0, b=0.01)\n",
        "        self.fc5.bias.data.fill_(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = F.relu(self.fc4(x))\n",
        "      x = F.relu(self.fc5(x))\n",
        "      return x\n",
        "\n",
        "    def calculateUtility(self,peak_arr, output):\n",
        "        ## for agent i, peaks of all datasampes\n",
        "        ## peak_arr :  n_samples x 1\n",
        "        ### output : n_samples x K\n",
        "        loss = torch.tensor([])\n",
        "        if use_cuda:\n",
        "          loss = loss.cuda()\n",
        "\n",
        "        ## For each facility calcuate loss\n",
        "        for k in range(self.K):        \n",
        "          k_facility_location = output[k:k+1]\n",
        "          appendloss = torch.add(peak_arr,-k_facility_location)    \n",
        "          loss  = torch.cat([loss,appendloss ], axis = 0)\n",
        "        loss = torch.abs(loss)\n",
        "        loss = torch.reshape(loss, (self.K,self.n_agents) )\n",
        "        ## take minimum loss amoung all k facility i.e. loss corresponding to closest facility to peak\n",
        "        loss , indices = torch.min(loss, axis=0)\n",
        "        utility = -loss\n",
        "        return utility\n",
        "    \n",
        "    def calculateRegret(self,y,x, betas):\n",
        "      ## y : is output location of K facility for all n_samples  n_samples x K\n",
        "      ### x is n_samples x n_agents (peaks of data)\n",
        "      ### betas - that are sampled to calculate regret\n",
        "      ### we will calculate regret only if a peak matches any of betas, and then misreported peaks becomes rest of the betas\n",
        "      ## Examples if betas is [0.2 , 0.4, 0.6, 0.8 , 1]\n",
        "      ## and peak is [0.4] then you go ahead and find regret with misreported values [0.2,0.6,0.8,1]\n",
        "      ## For practicality, we keep a threshold , instead of fully matching betas and peaks\n",
        "\n",
        "      ## From the paper \n",
        "      ### For each example j, (5) computes the maximum utility agent i could gain if her true peak was one\n",
        "      ### of β1;...; βM and she chose to misreport it as one of β1,..., βM.\n",
        "\n",
        "      regret = []\n",
        "      threshold = 0.01\n",
        "      ## For each agent\n",
        "      for i in range(self.n_agents):\n",
        "        ## fetch their peaks\n",
        "        peak_of_agent_i = x[ :, i:i+1]\n",
        "        count = 0\n",
        "        regret_for_agent_i = []\n",
        "\n",
        "        ## For each peak, \n",
        "        for j, peak in enumerate(peak_of_agent_i):\n",
        "          valuedifference = torch.add(betas, -peak)\n",
        "          isValuePresentWithThreshold = torch.abs(valuedifference) <= threshold\n",
        "          ## Find if peak matches any value in betas\n",
        "          if True in isValuePresentWithThreshold:\n",
        "            count += 1\n",
        "            index =  torch.where(isValuePresentWithThreshold == True)\n",
        "            ## to calucate regret\n",
        "            regret_for_an_sample = []\n",
        "\n",
        "            ## calculate regret for all other values of betas \n",
        "            for b in range(self.M):\n",
        "              if( b != index[0][0]):\n",
        "                datasample = x[j].clone()\n",
        "                \n",
        "                ## misreported output location Kx1\n",
        "                misreporteddatasample = datasample.clone()\n",
        "                misreporteddatasample[i] = betas[b]\n",
        "                misrerpoted_output = self.forward(misreporteddatasample)\n",
        "                \n",
        "                ## acutal output location K x 1\n",
        "                actualdatasample = datasample.clone()\n",
        "                actualdatasample[i] = betas[index[0][0]]\n",
        "                actualdata_output = self.forward(actualdatasample)\n",
        "\n",
        "                ## utility will be calcuated considering the actual peak 1x1\n",
        "                misreported_utility = self.calculateUtility(actualdatasample,misrerpoted_output)\n",
        "                actual_utility = self.calculateUtility(actualdatasample,actualdata_output)\n",
        "\n",
        "                difference_for_agent_i = misreported_utility[i] -   actual_utility[i]\n",
        "                regret_for_an_sample.append(difference_for_agent_i)\n",
        "\n",
        "            regret_for_an_sample = torch.FloatTensor(regret_for_an_sample)\n",
        "            ## for all the misreported peaks, chose the maximum regret for that sample\n",
        "            regret_for_an_sample = torch.max(regret_for_an_sample)\n",
        "            ## append it to the regret of agent \n",
        "            regret_for_agent_i.append(regret_for_an_sample)\n",
        "          else:\n",
        "            ## when peaks doesnt matches any betas, we simply append 0 peak\n",
        "            regret_for_agent_i.append(0)\n",
        "        \n",
        "\n",
        "        regret_for_agent_i = torch.FloatTensor(regret_for_agent_i)\n",
        "        # regret_for_an_sample = torch.mean(regret_for_an_sample)\n",
        "        # taking mean over all samples for agent and append to regret\n",
        "        regret_for_agent_i = torch.mean(regret_for_agent_i)\n",
        "        regret.append(regret_for_agent_i)\n",
        "        print('For agent ' , i , ' no of beta matches with peak', count)\n",
        "      print('regret is ', regret)\n",
        "\n",
        "      regret = torch.FloatTensor(regret)\n",
        "      maxregretamoungagents = torch.max(regret)\n",
        "      print('max regret amoung agents', maxregretamoungagents)\n",
        "      return regret, maxregretamoungagents\n",
        "\n",
        "\n",
        "\n",
        "    def loss_function(self, y, x, _lamdda , _rho):\n",
        "\n",
        "      ## Betas for calculating regret\n",
        "      betas =  np.random.rand(self.M)\n",
        "      betas = torch.FloatTensor(betas)\n",
        "      if use_cuda:\n",
        "        betas = betas.cuda()\n",
        "      print('betas', betas)\n",
        "\n",
        "      regret , maxregretamoungagents = self.calculateRegret(y,x,betas)\n",
        "\n",
        "      ## calculatting social cost the same way we did in moulin net\n",
        "      loss = torch.tensor([]).cuda()\n",
        "      for k in range(self.K):        \n",
        "        loss_for_k_facility = y[:,k:k+1]\n",
        "        appendloss = torch.add(x,-loss_for_k_facility)    \n",
        "        loss  = torch.cat([loss,appendloss ], axis = 1)\n",
        "      loss = torch.abs(loss)\n",
        "      loss = torch.reshape(loss, (x.shape[0],self.K,self.n_agents) )\n",
        "      loss , indices = torch.min(loss, axis=1)\n",
        "      loss = torch.mean((torch.sum(  loss , dim=1))/self.n_agents)\n",
        "\n",
        "      print('social cost ' , loss)\n",
        "\n",
        "      loss = loss + (maxregretamoungagents * _lamdda) +  ( maxregretamoungagents**2 ) * _rho\n",
        "      return loss, maxregretamoungagents\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rNARmJmDAsa",
        "colab_type": "code",
        "outputId": "a5f6f44e-6ab2-4290-cabf-492a7110a8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "### Train and Testing of Moulin Net\n",
        "\n",
        "K = 1\n",
        "net = MoulinNet(n_agents,K)\n",
        "epochs = 40\n",
        "learning_rate = 0.1\n",
        "\n",
        "def moulin_train(X_train,epochs=epochs, learning_rate=learning_rate):\n",
        "  optimizer = optim.Adam(net.parameters(), lr= learning_rate)\n",
        "  with torch.autograd.set_detect_anomaly(True):\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = net(X_train)\n",
        "        train_loss = net.loss_function(y_pred,X_train)    \n",
        "        print( 'Epoch : ', epoch ,  'training loss ', train_loss)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def moulin_test(X_test):\n",
        "    y_test = net(X_test)\n",
        "    test_loss = net.loss_function(y_test,X_test)    \n",
        "    print('Testing Loss is ', test_loss)\n",
        "\n",
        "\n",
        "moulin_train(moulin_train_data)\n",
        "moulin_test(moulin_test_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  0 training loss  tensor(0.3000, grad_fn=<MeanBackward0>)\n",
            "Epoch :  1 training loss  tensor(0.2614, grad_fn=<MeanBackward0>)\n",
            "Epoch :  2 training loss  tensor(0.2434, grad_fn=<MeanBackward0>)\n",
            "Epoch :  3 training loss  tensor(0.2357, grad_fn=<MeanBackward0>)\n",
            "Epoch :  4 training loss  tensor(0.2329, grad_fn=<MeanBackward0>)\n",
            "Epoch :  5 training loss  tensor(0.2293, grad_fn=<MeanBackward0>)\n",
            "Epoch :  6 training loss  tensor(0.2269, grad_fn=<MeanBackward0>)\n",
            "Epoch :  7 training loss  tensor(0.2165, grad_fn=<MeanBackward0>)\n",
            "Epoch :  8 training loss  tensor(0.2056, grad_fn=<MeanBackward0>)\n",
            "Epoch :  9 training loss  tensor(0.2042, grad_fn=<MeanBackward0>)\n",
            "Epoch :  10 training loss  tensor(0.2039, grad_fn=<MeanBackward0>)\n",
            "Epoch :  11 training loss  tensor(0.2034, grad_fn=<MeanBackward0>)\n",
            "Epoch :  12 training loss  tensor(0.2028, grad_fn=<MeanBackward0>)\n",
            "Epoch :  13 training loss  tensor(0.2017, grad_fn=<MeanBackward0>)\n",
            "Epoch :  14 training loss  tensor(0.2005, grad_fn=<MeanBackward0>)\n",
            "Epoch :  15 training loss  tensor(0.1993, grad_fn=<MeanBackward0>)\n",
            "Epoch :  16 training loss  tensor(0.1985, grad_fn=<MeanBackward0>)\n",
            "Epoch :  17 training loss  tensor(0.1982, grad_fn=<MeanBackward0>)\n",
            "Epoch :  18 training loss  tensor(0.1980, grad_fn=<MeanBackward0>)\n",
            "Epoch :  19 training loss  tensor(0.1979, grad_fn=<MeanBackward0>)\n",
            "Epoch :  20 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  21 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  22 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  23 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  24 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  25 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  26 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  27 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  28 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  29 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  30 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  31 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  32 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  33 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  34 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  35 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  36 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  37 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  38 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Epoch :  39 training loss  tensor(0.1978, grad_fn=<MeanBackward0>)\n",
            "Testing Loss is  tensor(0.1997, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLCEJ-fBDyBz",
        "colab_type": "code",
        "outputId": "ac098039-198b-4175-ed82-cd742c3601f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "### Train and Test Regret net\n",
        "### mini batch training\n",
        "K = 1\n",
        "mini_batch_size  = 500\n",
        "lr = 0.005\n",
        "epochs = 40\n",
        "_rho = 0.0005\n",
        "\n",
        "\n",
        "net = RegretNet(n_agents,K)\n",
        "if use_cuda:\n",
        "    net = net.cuda()\n",
        "\n",
        "def create_mini_batches(data, batch_size): \n",
        "    mini_batches = [] \n",
        "    indices = np.random.permutation(data.shape[0])\n",
        "    n_minibatches = data.shape[0] // batch_size   \n",
        "    for i in range(n_minibatches ): \n",
        "        mini_batch_idx= indices[i * batch_size:(i + 1)*batch_size]\n",
        "        mini_batch = data[ mini_batch_idx, :] \n",
        "        mini_batches.append(mini_batch) \n",
        "    return mini_batches \n",
        "\n",
        "\n",
        "## decay learning rate\n",
        "def adjust_learning_rate(optimizer, epoch,  no_iterations, quantity, lr= lr):\n",
        "    lr = lr * (quantity ** (epoch // no_iterations))\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = lr\n",
        "      print('current learning rate ', lr)\n",
        "\n",
        "\n",
        "def regretnet_train(X_train,epochs=epochs, learning_rate=lr, ):\n",
        "\n",
        "  _lamdda = 0.1\n",
        "  optimizer = optim.Adam(net.parameters(), lr= learning_rate)\n",
        "  with torch.autograd.set_detect_anomaly(True):\n",
        "    for epoch in range(epochs):\n",
        "        totalerror = []\n",
        "        minibatches = create_mini_batches(X_train,mini_batch_size )\n",
        "        for minibatch in minibatches:\n",
        "          optimizer.zero_grad()\n",
        "          ## decay lr after some epochs\n",
        "          adjust_learning_rate(optimizer, epoch, 10, 0.99)\n",
        "\n",
        "          y_pred = net(minibatch)\n",
        "          train_loss , maxregret = net.loss_function(y_pred,minibatch,_lamdda,_rho)    \n",
        "\n",
        "          ## total error for a epoch\n",
        "          totalerror.append(train_loss)\n",
        "\n",
        "          train_loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          print('Epoch : ', epoch , 'minibatch loss  ', train_loss)\n",
        "        totalerror = torch.FloatTensor(totalerror)\n",
        "        print( 'Epoch : ', epoch ,  'training loss ', torch.mean(totalerror))\n",
        "\n",
        "        ## Update rule for lambda\n",
        "        if(epoch % 5 == 0):\n",
        "          print(' current lambda', _lamdda , ' to minus ',  _rho* maxregret)\n",
        "          _lamdda = _lamdda - _rho* maxregret\n",
        "          print(' _lamdda value ', _lamdda)\n",
        "  return _lamdda        \n",
        "\n",
        "\n",
        "\n",
        "def regretnet_test(X_test):\n",
        "    y_test = net(X_test)\n",
        "    test_loss, maxregret = net.loss_function(y_test,X_test,_lamdda,_rho)\n",
        "    print('Testing Loss is ', test_loss)\n",
        "    print('max regret is ', maxregret)\n",
        "\n",
        "\n",
        "_lamdda = regretnet_train(regretnet_train_data.cuda())\n",
        "regretnet_test(regretnet_test_data.cuda())\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current learning rate  0.005\n",
            "betas tensor([0.3734, 0.2209, 0.6043, 0.5474, 0.3748], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 40\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 38\n",
            "For agent  3  no of beta matches with peak 32\n",
            "For agent  4  no of beta matches with peak 41\n",
            "regret is  [tensor(8.6188e-08), tensor(8.3655e-08), tensor(1.2296e-07), tensor(7.7814e-08), tensor(1.4436e-07)]\n",
            "max regret amoung agents tensor(1.4436e-07)\n",
            "social cost  tensor(0.3997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  0 minibatch loss   tensor(0.3997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.7304, 0.9506, 0.6830, 0.9985, 0.1749], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 39\n",
            "For agent  1  no of beta matches with peak 34\n",
            "For agent  2  no of beta matches with peak 61\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(1.1557e-06), tensor(-3.5739e-07), tensor(1.7964e-06), tensor(5.7882e-07), tensor(-1.2634e-06)]\n",
            "max regret amoung agents tensor(1.7964e-06)\n",
            "social cost  tensor(0.3541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  0 minibatch loss   tensor(0.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.2035, 0.4356, 0.0709, 0.9686, 0.5420], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 57\n",
            "For agent  3  no of beta matches with peak 62\n",
            "For agent  4  no of beta matches with peak 50\n",
            "regret is  [tensor(3.4187e-05), tensor(1.9380e-05), tensor(1.8766e-05), tensor(2.6795e-05), tensor(2.6500e-05)]\n",
            "max regret amoung agents tensor(3.4187e-05)\n",
            "social cost  tensor(0.3039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  0 minibatch loss   tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  0 training loss  tensor(0.3526)\n",
            " current lambda 0.1  to minus  tensor(1.7093e-08)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.6710, 0.1687, 0.2995, 0.9379, 0.3927], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 60\n",
            "For agent  1  no of beta matches with peak 40\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 45\n",
            "For agent  4  no of beta matches with peak 54\n",
            "regret is  [tensor(4.9802e-06), tensor(2.9001e-05), tensor(5.4710e-05), tensor(4.8115e-05), tensor(4.4505e-05)]\n",
            "max regret amoung agents tensor(5.4710e-05)\n",
            "social cost  tensor(0.2581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  1 minibatch loss   tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.8290, 0.5158, 0.2570, 0.9085, 0.2319], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 42\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(0.0001), tensor(6.1816e-05), tensor(8.8739e-05), tensor(0.0002), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  1 minibatch loss   tensor(0.2577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.1100, 0.5204, 0.9626, 0.6048, 0.2004], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 42\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 50\n",
            "regret is  [tensor(0.0004), tensor(5.5202e-05), tensor(-2.6165e-05), tensor(0.0002), tensor(0.0004)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  1 minibatch loss   tensor(0.2838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  1 training loss  tensor(0.2665)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.9000, 0.4622, 0.4023, 0.6122, 0.2075], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 71\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 41\n",
            "regret is  [tensor(0.0002), tensor(7.3562e-05), tensor(9.0955e-05), tensor(0.0002), tensor(7.6990e-05)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  2 minibatch loss   tensor(0.2621, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.0530, 0.2304, 0.9266, 0.7053, 0.4282], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 40\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 56\n",
            "regret is  [tensor(3.7428e-05), tensor(9.2936e-05), tensor(7.5896e-05), tensor(4.1359e-05), tensor(9.8458e-05)]\n",
            "max regret amoung agents tensor(9.8458e-05)\n",
            "social cost  tensor(0.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  2 minibatch loss   tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.1910, 0.6572, 0.8296, 0.0295, 0.2807], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 57\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 65\n",
            "regret is  [tensor(3.1754e-05), tensor(1.7787e-05), tensor(2.7946e-05), tensor(4.8584e-05), tensor(4.5549e-05)]\n",
            "max regret amoung agents tensor(4.8584e-05)\n",
            "social cost  tensor(0.2505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  2 minibatch loss   tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  2 training loss  tensor(0.2532)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.6456, 0.5930, 0.0075, 0.5229, 0.6338], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 39\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 50\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 57\n",
            "regret is  [tensor(-1.5846e-05), tensor(-2.2822e-05), tensor(-3.4751e-05), tensor(-2.2974e-06), tensor(-3.7496e-05)]\n",
            "max regret amoung agents tensor(-2.2974e-06)\n",
            "social cost  tensor(0.2538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  3 minibatch loss   tensor(0.2538, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.1012, 0.7621, 0.9686, 0.1329, 0.3952], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 46\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 59\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 36\n",
            "regret is  [tensor(2.9992e-05), tensor(2.9877e-05), tensor(2.8924e-05), tensor(3.8696e-05), tensor(3.5134e-05)]\n",
            "max regret amoung agents tensor(3.8696e-05)\n",
            "social cost  tensor(0.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  3 minibatch loss   tensor(0.2608, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.9026, 0.2328, 0.0928, 0.0796, 0.5221], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 36\n",
            "For agent  1  no of beta matches with peak 58\n",
            "For agent  2  no of beta matches with peak 47\n",
            "For agent  3  no of beta matches with peak 63\n",
            "For agent  4  no of beta matches with peak 43\n",
            "regret is  [tensor(-2.9531e-06), tensor(6.9332e-06), tensor(5.2841e-06), tensor(1.3394e-05), tensor(1.4452e-05)]\n",
            "max regret amoung agents tensor(1.4452e-05)\n",
            "social cost  tensor(0.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  3 minibatch loss   tensor(0.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  3 training loss  tensor(0.2608)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.7332, 0.5682, 0.4469, 0.7064, 0.8590], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 57\n",
            "For agent  1  no of beta matches with peak 53\n",
            "For agent  2  no of beta matches with peak 47\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 59\n",
            "regret is  [tensor(4.0698e-05), tensor(3.9763e-05), tensor(3.6096e-05), tensor(2.0983e-05), tensor(4.1827e-05)]\n",
            "max regret amoung agents tensor(4.1827e-05)\n",
            "social cost  tensor(0.2600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  4 minibatch loss   tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.2273, 0.8797, 0.1325, 0.9953, 0.3945], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 56\n",
            "For agent  1  no of beta matches with peak 59\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 49\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(1.9410e-05), tensor(9.0048e-06), tensor(2.0733e-05), tensor(1.8949e-05), tensor(1.9626e-05)]\n",
            "max regret amoung agents tensor(2.0733e-05)\n",
            "social cost  tensor(0.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  4 minibatch loss   tensor(0.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.0340, 0.7439, 0.6489, 0.6010, 0.1193], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 52\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 33\n",
            "For agent  4  no of beta matches with peak 54\n",
            "regret is  [tensor(4.8122e-06), tensor(7.5623e-06), tensor(1.3435e-05), tensor(3.8288e-06), tensor(8.3323e-06)]\n",
            "max regret amoung agents tensor(1.3435e-05)\n",
            "social cost  tensor(0.2475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  4 minibatch loss   tensor(0.2475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  4 training loss  tensor(0.2567)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.4825, 0.3496, 0.1339, 0.2255, 0.6927], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 55\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(3.5190e-06), tensor(1.1962e-05), tensor(2.6932e-05), tensor(2.1675e-05), tensor(6.6471e-06)]\n",
            "max regret amoung agents tensor(2.6932e-05)\n",
            "social cost  tensor(0.2484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  5 minibatch loss   tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.5662, 0.7634, 0.5956, 0.5989, 0.1977], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 41\n",
            "For agent  1  no of beta matches with peak 40\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 34\n",
            "regret is  [tensor(-2.6950e-05), tensor(-8.6889e-06), tensor(-2.6917e-05), tensor(-1.6738e-05), tensor(-1.2603e-05)]\n",
            "max regret amoung agents tensor(-8.6889e-06)\n",
            "social cost  tensor(0.2486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  5 minibatch loss   tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.1477, 0.3642, 0.5999, 0.5798, 0.1093], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 61\n",
            "For agent  3  no of beta matches with peak 37\n",
            "For agent  4  no of beta matches with peak 41\n",
            "regret is  [tensor(6.7414e-06), tensor(2.4825e-05), tensor(1.9249e-05), tensor(2.8519e-05), tensor(1.4902e-05)]\n",
            "max regret amoung agents tensor(2.8519e-05)\n",
            "social cost  tensor(0.2499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  5 minibatch loss   tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  5 training loss  tensor(0.2490)\n",
            " current lambda tensor(0.1000)  to minus  tensor(1.4259e-08)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.5575, 0.4711, 0.1299, 0.2919, 0.8045], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 61\n",
            "For agent  4  no of beta matches with peak 40\n",
            "regret is  [tensor(3.2711e-05), tensor(4.8987e-05), tensor(9.7565e-05), tensor(0.0001), tensor(8.5136e-05)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  6 minibatch loss   tensor(0.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.8261, 0.0895, 0.3373, 0.8979, 0.7102], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(1.5628e-05), tensor(4.2604e-05), tensor(3.6374e-05), tensor(2.8949e-05), tensor(2.3149e-05)]\n",
            "max regret amoung agents tensor(4.2604e-05)\n",
            "social cost  tensor(0.2543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  6 minibatch loss   tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.4821, 0.9405, 0.4426, 0.5957, 0.8809], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 59\n",
            "For agent  1  no of beta matches with peak 59\n",
            "For agent  2  no of beta matches with peak 57\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 62\n",
            "regret is  [tensor(5.0321e-05), tensor(2.9950e-05), tensor(3.2142e-05), tensor(1.9105e-05), tensor(2.6253e-05)]\n",
            "max regret amoung agents tensor(5.0321e-05)\n",
            "social cost  tensor(0.2501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  6 minibatch loss   tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  6 training loss  tensor(0.2532)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.1924, 0.3666, 0.1287, 0.0479, 0.9643], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 58\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 41\n",
            "For agent  3  no of beta matches with peak 45\n",
            "For agent  4  no of beta matches with peak 50\n",
            "regret is  [tensor(-3.8149e-05), tensor(-6.1212e-05), tensor(-1.1279e-05), tensor(-2.7250e-05), tensor(3.6901e-05)]\n",
            "max regret amoung agents tensor(3.6901e-05)\n",
            "social cost  tensor(0.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  7 minibatch loss   tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.4779, 0.8040, 0.7675, 0.2611, 0.0493], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 60\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(3.8110e-05), tensor(5.7650e-05), tensor(3.4057e-05), tensor(4.0279e-05), tensor(5.8048e-05)]\n",
            "max regret amoung agents tensor(5.8048e-05)\n",
            "social cost  tensor(0.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  7 minibatch loss   tensor(0.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.9390, 0.7995, 0.2548, 0.9293, 0.3947], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 47\n",
            "For agent  1  no of beta matches with peak 45\n",
            "For agent  2  no of beta matches with peak 57\n",
            "For agent  3  no of beta matches with peak 55\n",
            "For agent  4  no of beta matches with peak 41\n",
            "regret is  [tensor(8.5154e-06), tensor(1.8544e-05), tensor(7.2022e-06), tensor(1.2140e-05), tensor(4.6871e-06)]\n",
            "max regret amoung agents tensor(1.8544e-05)\n",
            "social cost  tensor(0.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  7 minibatch loss   tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  7 training loss  tensor(0.2489)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.8557, 0.8265, 0.8370, 0.2643, 0.8818], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 56\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 57\n",
            "regret is  [tensor(-3.7961e-05), tensor(-1.8818e-05), tensor(-4.4541e-05), tensor(-3.5520e-05), tensor(-4.2621e-05)]\n",
            "max regret amoung agents tensor(-1.8818e-05)\n",
            "social cost  tensor(0.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  8 minibatch loss   tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.9447, 0.4180, 0.2949, 0.7835, 0.9904], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 50\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 59\n",
            "regret is  [tensor(1.2314e-05), tensor(1.2315e-05), tensor(7.9474e-06), tensor(8.2214e-06), tensor(1.7056e-05)]\n",
            "max regret amoung agents tensor(1.7056e-05)\n",
            "social cost  tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  8 minibatch loss   tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.3352, 0.2051, 0.1959, 0.1035, 0.8298], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 53\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 61\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 42\n",
            "regret is  [tensor(-1.2339e-05), tensor(-1.8106e-05), tensor(-1.9363e-05), tensor(-1.6475e-06), tensor(-8.6963e-06)]\n",
            "max regret amoung agents tensor(-1.6475e-06)\n",
            "social cost  tensor(0.2531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  8 minibatch loss   tensor(0.2531, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  8 training loss  tensor(0.2498)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.8100, 0.5398, 0.7807, 0.6001, 0.4518], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 63\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 37\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(2.8718e-05), tensor(1.7577e-05), tensor(1.8050e-05), tensor(2.0359e-05), tensor(1.6701e-05)]\n",
            "max regret amoung agents tensor(2.8718e-05)\n",
            "social cost  tensor(0.2502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  9 minibatch loss   tensor(0.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.7938, 0.5382, 0.2865, 0.2000, 0.5968], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 58\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 50\n",
            "For agent  3  no of beta matches with peak 37\n",
            "For agent  4  no of beta matches with peak 37\n",
            "regret is  [tensor(9.9030e-06), tensor(8.7434e-06), tensor(1.4327e-05), tensor(1.1674e-05), tensor(1.5668e-05)]\n",
            "max regret amoung agents tensor(1.5668e-05)\n",
            "social cost  tensor(0.2471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  9 minibatch loss   tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.005\n",
            "betas tensor([0.5185, 0.8012, 0.3302, 0.1254, 0.3665], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 37\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(1.0760e-05), tensor(6.3523e-06), tensor(1.4475e-05), tensor(1.2323e-05), tensor(4.1083e-05)]\n",
            "max regret amoung agents tensor(4.1083e-05)\n",
            "social cost  tensor(0.2508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  9 minibatch loss   tensor(0.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  9 training loss  tensor(0.2494)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.8177, 0.7597, 0.8611, 0.9023, 0.6532], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 42\n",
            "For agent  1  no of beta matches with peak 54\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 37\n",
            "regret is  [tensor(2.8803e-05), tensor(4.2465e-05), tensor(3.7764e-05), tensor(4.5859e-05), tensor(3.6114e-05)]\n",
            "max regret amoung agents tensor(4.5859e-05)\n",
            "social cost  tensor(0.2455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  10 minibatch loss   tensor(0.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.4182, 0.9323, 0.4680, 0.3933, 0.3633], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 46\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 56\n",
            "regret is  [tensor(-1.9847e-05), tensor(-9.0289e-07), tensor(-4.1307e-05), tensor(-2.8134e-05), tensor(-3.7690e-05)]\n",
            "max regret amoung agents tensor(-9.0289e-07)\n",
            "social cost  tensor(0.2440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  10 minibatch loss   tensor(0.2440, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.7569, 0.6476, 0.1577, 0.5657, 0.6967], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 54\n",
            "For agent  1  no of beta matches with peak 61\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 38\n",
            "regret is  [tensor(-4.6400e-05), tensor(-1.5828e-05), tensor(5.1391e-07), tensor(-7.4701e-06), tensor(1.1868e-05)]\n",
            "max regret amoung agents tensor(1.1868e-05)\n",
            "social cost  tensor(0.2541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  10 minibatch loss   tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  10 training loss  tensor(0.2479)\n",
            " current lambda tensor(0.1000)  to minus  tensor(5.9339e-09)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.7074, 0.7624, 0.3914, 0.8521, 0.6797], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 56\n",
            "For agent  3  no of beta matches with peak 55\n",
            "For agent  4  no of beta matches with peak 54\n",
            "regret is  [tensor(-8.6318e-06), tensor(7.3781e-06), tensor(-8.2536e-06), tensor(-4.3577e-06), tensor(1.4948e-05)]\n",
            "max regret amoung agents tensor(1.4948e-05)\n",
            "social cost  tensor(0.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  11 minibatch loss   tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.3872, 0.4432, 0.6082, 0.1455, 0.4706], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 44\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 39\n",
            "regret is  [tensor(7.2387e-05), tensor(8.9926e-05), tensor(7.9166e-05), tensor(8.2958e-05), tensor(6.1008e-05)]\n",
            "max regret amoung agents tensor(8.9926e-05)\n",
            "social cost  tensor(0.2521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  11 minibatch loss   tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.8303, 0.0782, 0.4846, 0.9423, 0.4695], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 47\n",
            "For agent  1  no of beta matches with peak 52\n",
            "For agent  2  no of beta matches with peak 32\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(4.0076e-05), tensor(0.0001), tensor(4.6890e-05), tensor(1.8131e-05), tensor(4.6351e-05)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  11 minibatch loss   tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  11 training loss  tensor(0.2486)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.0698, 0.5555, 0.5900, 0.2589, 0.1033], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 61\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 38\n",
            "For agent  4  no of beta matches with peak 46\n",
            "regret is  [tensor(2.9270e-05), tensor(3.5148e-05), tensor(3.0024e-05), tensor(7.3773e-06), tensor(4.9314e-05)]\n",
            "max regret amoung agents tensor(4.9314e-05)\n",
            "social cost  tensor(0.2471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  12 minibatch loss   tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.1064, 0.5610, 0.2486, 0.9053, 0.8563], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 36\n",
            "regret is  [tensor(3.3628e-05), tensor(5.6110e-05), tensor(4.8729e-05), tensor(2.4772e-05), tensor(8.3029e-05)]\n",
            "max regret amoung agents tensor(8.3029e-05)\n",
            "social cost  tensor(0.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  12 minibatch loss   tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.5722, 0.2781, 0.5426, 0.2791, 0.0224], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 38\n",
            "For agent  2  no of beta matches with peak 37\n",
            "For agent  3  no of beta matches with peak 43\n",
            "For agent  4  no of beta matches with peak 36\n",
            "regret is  [tensor(5.2792e-06), tensor(2.3842e-10), tensor(2.9978e-05), tensor(1.0883e-06), tensor(1.5923e-05)]\n",
            "max regret amoung agents tensor(2.9978e-05)\n",
            "social cost  tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  12 minibatch loss   tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  12 training loss  tensor(0.2476)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.3034, 0.6227, 0.8849, 0.0190, 0.0018], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 38\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 37\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(1.7590e-05), tensor(3.3491e-05), tensor(2.6353e-05), tensor(5.1132e-05), tensor(5.4746e-05)]\n",
            "max regret amoung agents tensor(5.4746e-05)\n",
            "social cost  tensor(0.2465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  13 minibatch loss   tensor(0.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.5542, 0.1610, 0.9232, 0.9231, 0.8114], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 33\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 42\n",
            "For agent  3  no of beta matches with peak 38\n",
            "For agent  4  no of beta matches with peak 37\n",
            "regret is  [tensor(-1.7210e-05), tensor(-1.2378e-05), tensor(2.5600e-05), tensor(3.8265e-05), tensor(8.0217e-05)]\n",
            "max regret amoung agents tensor(8.0217e-05)\n",
            "social cost  tensor(0.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  13 minibatch loss   tensor(0.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.9381, 0.3015, 0.1639, 0.8947, 0.3172], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 39\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 42\n",
            "regret is  [tensor(3.0081e-05), tensor(8.7069e-06), tensor(9.5866e-06), tensor(1.3668e-05), tensor(3.1096e-05)]\n",
            "max regret amoung agents tensor(3.1096e-05)\n",
            "social cost  tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  13 minibatch loss   tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  13 training loss  tensor(0.2474)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.2080, 0.2450, 0.9824, 0.6516, 0.5209], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 54\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 59\n",
            "For agent  3  no of beta matches with peak 45\n",
            "For agent  4  no of beta matches with peak 48\n",
            "regret is  [tensor(9.1898e-05), tensor(3.4635e-05), tensor(5.9258e-05), tensor(7.4586e-05), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  14 minibatch loss   tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.5166, 0.5474, 0.0663, 0.8460, 0.7834], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 52\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 53\n",
            "For agent  4  no of beta matches with peak 62\n",
            "regret is  [tensor(2.7129e-05), tensor(6.6266e-05), tensor(-9.1111e-05), tensor(9.8152e-05), tensor(8.1506e-05)]\n",
            "max regret amoung agents tensor(9.8152e-05)\n",
            "social cost  tensor(0.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  14 minibatch loss   tensor(0.2483, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.7776, 0.9393, 0.4504, 0.9746, 0.0509], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 58\n",
            "For agent  1  no of beta matches with peak 56\n",
            "For agent  2  no of beta matches with peak 57\n",
            "For agent  3  no of beta matches with peak 60\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(3.2981e-05), tensor(6.0822e-05), tensor(2.7611e-06), tensor(3.7703e-05), tensor(9.3756e-05)]\n",
            "max regret amoung agents tensor(9.3756e-05)\n",
            "social cost  tensor(0.2469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  14 minibatch loss   tensor(0.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  14 training loss  tensor(0.2465)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.6296, 0.3705, 0.8956, 0.5453, 0.1417], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 43\n",
            "For agent  3  no of beta matches with peak 63\n",
            "For agent  4  no of beta matches with peak 48\n",
            "regret is  [tensor(7.1756e-05), tensor(0.0001), tensor(0.0001), tensor(7.8258e-05), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  15 minibatch loss   tensor(0.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.8953, 0.6461, 0.4922, 0.6922, 0.8005], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 39\n",
            "For agent  1  no of beta matches with peak 54\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(9.1281e-05), tensor(7.6030e-05), tensor(6.2849e-05), tensor(7.9175e-05), tensor(5.7029e-05)]\n",
            "max regret amoung agents tensor(9.1281e-05)\n",
            "social cost  tensor(0.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  15 minibatch loss   tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.7903, 0.6392, 0.2315, 0.4219, 0.3344], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 61\n",
            "For agent  1  no of beta matches with peak 52\n",
            "For agent  2  no of beta matches with peak 41\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(4.2237e-05), tensor(5.5975e-05), tensor(1.6252e-05), tensor(6.1416e-05), tensor(4.4664e-05)]\n",
            "max regret amoung agents tensor(6.1416e-05)\n",
            "social cost  tensor(0.2427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  15 minibatch loss   tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  15 training loss  tensor(0.2458)\n",
            " current lambda tensor(0.1000)  to minus  tensor(3.0708e-08)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.8115, 0.9934, 0.7559, 0.8455, 0.6038], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 42\n",
            "For agent  4  no of beta matches with peak 43\n",
            "regret is  [tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  16 minibatch loss   tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.3800, 0.9032, 0.3213, 0.4932, 0.9950], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 42\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 60\n",
            "For agent  4  no of beta matches with peak 40\n",
            "regret is  [tensor(2.9569e-05), tensor(0.0001), tensor(5.3470e-05), tensor(0.0001), tensor(7.6134e-05)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  16 minibatch loss   tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.5733, 0.7667, 0.8534, 0.4838, 0.8818], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 56\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 63\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(0.0002), tensor(9.7127e-05), tensor(0.0001), tensor(0.0001), tensor(9.5887e-05)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  16 minibatch loss   tensor(0.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  16 training loss  tensor(0.2448)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.6243, 0.5961, 0.0193, 0.6816, 0.1177], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 39\n",
            "For agent  4  no of beta matches with peak 56\n",
            "regret is  [tensor(2.1465e-05), tensor(2.0517e-05), tensor(8.8638e-05), tensor(3.4873e-05), tensor(2.4832e-06)]\n",
            "max regret amoung agents tensor(8.8638e-05)\n",
            "social cost  tensor(0.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  17 minibatch loss   tensor(0.2468, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.1943, 0.5803, 0.3572, 0.5090, 0.1892], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 46\n",
            "For agent  2  no of beta matches with peak 36\n",
            "For agent  3  no of beta matches with peak 36\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(8.5788e-05), tensor(0.0001), tensor(6.0225e-05), tensor(0.0001), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  17 minibatch loss   tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.6553, 0.3572, 0.4443, 0.8099, 0.0181], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 52\n",
            "For agent  2  no of beta matches with peak 41\n",
            "For agent  3  no of beta matches with peak 36\n",
            "For agent  4  no of beta matches with peak 59\n",
            "regret is  [tensor(0.0001), tensor(0.0004), tensor(0.0001), tensor(0.0001), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  17 minibatch loss   tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  17 training loss  tensor(0.2438)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.5005, 0.6273, 0.3942, 0.8984, 0.0584], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 64\n",
            "For agent  1  no of beta matches with peak 57\n",
            "For agent  2  no of beta matches with peak 47\n",
            "For agent  3  no of beta matches with peak 65\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(0.0002), tensor(0.0004), tensor(0.0002), tensor(-1.3975e-05), tensor(8.2511e-05)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  18 minibatch loss   tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.2373, 0.3914, 0.8145, 0.4333, 0.5827], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 65\n",
            "For agent  2  no of beta matches with peak 60\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(0.0002), tensor(-1.3888e-05), tensor(0.0002), tensor(2.0360e-05), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  18 minibatch loss   tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.0386, 0.4757, 0.4268, 0.2123, 0.1720], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 69\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 59\n",
            "regret is  [tensor(0.0005), tensor(0.0009), tensor(0.0006), tensor(0.0007), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0009)\n",
            "social cost  tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  18 minibatch loss   tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  18 training loss  tensor(0.2425)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.9827, 0.0114, 0.1560, 0.4348, 0.4347], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 53\n",
            "For agent  2  no of beta matches with peak 39\n",
            "For agent  3  no of beta matches with peak 30\n",
            "For agent  4  no of beta matches with peak 48\n",
            "regret is  [tensor(-0.0002), tensor(-0.0001), tensor(1.1362e-05), tensor(4.9103e-05), tensor(-4.0504e-05)]\n",
            "max regret amoung agents tensor(4.9103e-05)\n",
            "social cost  tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  19 minibatch loss   tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.3277, 0.7395, 0.6410, 0.6139, 0.2089], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 61\n",
            "For agent  1  no of beta matches with peak 57\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(4.7636e-05), tensor(0.0001), tensor(7.1607e-06), tensor(0.0001), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0001)\n",
            "social cost  tensor(0.2381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  19 minibatch loss   tensor(0.2381, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.00495\n",
            "betas tensor([0.7448, 0.1522, 0.9728, 0.3452, 0.9828], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 47\n",
            "For agent  1  no of beta matches with peak 52\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 39\n",
            "regret is  [tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  19 minibatch loss   tensor(0.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  19 training loss  tensor(0.2410)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0959, 0.5837, 0.0564, 0.0103, 0.5231], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 68\n",
            "regret is  [tensor(0.0002), tensor(7.5315e-05), tensor(6.1990e-05), tensor(0.0002), tensor(0.0004)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  20 minibatch loss   tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.6188, 0.3546, 0.9575, 0.9033, 0.0377], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 60\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 43\n",
            "For agent  3  no of beta matches with peak 49\n",
            "For agent  4  no of beta matches with peak 55\n",
            "regret is  [tensor(0.0004), tensor(7.8140e-05), tensor(0.0003), tensor(0.0002), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  20 minibatch loss   tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.8897, 0.0317, 0.7426, 0.1563, 0.5733], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 54\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 53\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  20 minibatch loss   tensor(0.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  20 training loss  tensor(0.2395)\n",
            " current lambda tensor(0.1000)  to minus  tensor(1.3275e-07)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0750, 0.5726, 0.6558, 0.2865, 0.5405], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 54\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 60\n",
            "regret is  [tensor(0.0002), tensor(0.0001), tensor(7.8231e-05), tensor(-0.0001), tensor(1.8849e-05)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  21 minibatch loss   tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.2120, 0.3175, 0.5050, 0.8638, 0.1512], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 43\n",
            "For agent  1  no of beta matches with peak 70\n",
            "For agent  2  no of beta matches with peak 44\n",
            "For agent  3  no of beta matches with peak 48\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(-0.0001), tensor(9.6675e-05), tensor(4.3109e-05), tensor(0.0001), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  21 minibatch loss   tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0568, 0.2113, 0.7365, 0.0404, 0.1770], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 50\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(-0.0003), tensor(-0.0005), tensor(-0.0004), tensor(-7.3511e-05), tensor(-0.0004)]\n",
            "max regret amoung agents tensor(-7.3511e-05)\n",
            "social cost  tensor(0.2397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  21 minibatch loss   tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  21 training loss  tensor(0.2375)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.8858, 0.9452, 0.9206, 0.9793, 0.8793], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 44\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 40\n",
            "For agent  3  no of beta matches with peak 48\n",
            "For agent  4  no of beta matches with peak 41\n",
            "regret is  [tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  22 minibatch loss   tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.6638, 0.4294, 0.4048, 0.5910, 0.2923], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 65\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 48\n",
            "For agent  4  no of beta matches with peak 59\n",
            "regret is  [tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  22 minibatch loss   tensor(0.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.7873, 0.1963, 0.6699, 0.2999, 0.0941], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 39\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 53\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(0.0001), tensor(0.0001), tensor(9.4635e-05), tensor(0.0002), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  22 minibatch loss   tensor(0.2354, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  22 training loss  tensor(0.2358)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.2654, 0.4545, 0.1578, 0.7275, 0.1888], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 52\n",
            "For agent  1  no of beta matches with peak 53\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 66\n",
            "regret is  [tensor(9.4876e-05), tensor(6.7221e-05), tensor(4.6589e-05), tensor(0.0001), tensor(0.0005)]\n",
            "max regret amoung agents tensor(0.0005)\n",
            "social cost  tensor(0.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  23 minibatch loss   tensor(0.2385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.9926, 0.1040, 0.8621, 0.3625, 0.4956], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 43\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 40\n",
            "For agent  3  no of beta matches with peak 32\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(0.0002), tensor(0.0002), tensor(0.0006), tensor(0.0003), tensor(0.0007)]\n",
            "max regret amoung agents tensor(0.0007)\n",
            "social cost  tensor(0.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  23 minibatch loss   tensor(0.2276, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0689, 0.4554, 0.3338, 0.4157, 0.4665], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 37\n",
            "For agent  1  no of beta matches with peak 32\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 48\n",
            "For agent  4  no of beta matches with peak 40\n",
            "regret is  [tensor(0.0009), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0009)]\n",
            "max regret amoung agents tensor(0.0011)\n",
            "social cost  tensor(0.2356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  23 minibatch loss   tensor(0.2357, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  23 training loss  tensor(0.2339)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.3903, 0.8227, 0.4619, 0.3803, 0.3092], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 40\n",
            "For agent  2  no of beta matches with peak 42\n",
            "For agent  3  no of beta matches with peak 43\n",
            "For agent  4  no of beta matches with peak 38\n",
            "regret is  [tensor(-0.0003), tensor(-0.0003), tensor(-0.0002), tensor(-0.0002), tensor(-0.0003)]\n",
            "max regret amoung agents tensor(-0.0002)\n",
            "social cost  tensor(0.2361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  24 minibatch loss   tensor(0.2361, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0141, 0.6585, 0.2136, 0.0190, 0.9879], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 56\n",
            "For agent  2  no of beta matches with peak 36\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(0.0005), tensor(5.5823e-05), tensor(0.0002), tensor(0.0008), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0008)\n",
            "social cost  tensor(0.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  24 minibatch loss   tensor(0.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.2490, 0.2846, 0.8589, 0.8254, 0.8258], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 42\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 44\n",
            "For agent  3  no of beta matches with peak 39\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(4.1160e-05), tensor(-5.8617e-05), tensor(3.3542e-05), tensor(-2.4577e-05), tensor(3.6265e-05)]\n",
            "max regret amoung agents tensor(4.1160e-05)\n",
            "social cost  tensor(0.2251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  24 minibatch loss   tensor(0.2251, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  24 training loss  tensor(0.2323)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.1056, 0.6592, 0.1305, 0.0564, 0.2515], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 41\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 55\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(-0.0005), tensor(-0.0003), tensor(-0.0003), tensor(-0.0008), tensor(-0.0006)]\n",
            "max regret amoung agents tensor(-0.0003)\n",
            "social cost  tensor(0.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  25 minibatch loss   tensor(0.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.1832, 0.0502, 0.1218, 0.1835, 0.8995], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 40\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 42\n",
            "For agent  4  no of beta matches with peak 39\n",
            "regret is  [tensor(-0.0013), tensor(-0.0007), tensor(-0.0007), tensor(-0.0016), tensor(-0.0012)]\n",
            "max regret amoung agents tensor(-0.0007)\n",
            "social cost  tensor(0.2340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  25 minibatch loss   tensor(0.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.1405, 0.8787, 0.1112, 0.8916, 0.7955], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 52\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 66\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 46\n",
            "regret is  [tensor(0.0002), tensor(0.0003), tensor(0.0001), tensor(0.0002), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  25 minibatch loss   tensor(0.2303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  25 training loss  tensor(0.2309)\n",
            " current lambda tensor(0.1000)  to minus  tensor(1.2525e-07)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.2568, 0.8678, 0.6540, 0.8656, 0.3409], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 34\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 38\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 36\n",
            "regret is  [tensor(0.0003), tensor(0.0006), tensor(0.0001), tensor(0.0003), tensor(4.2226e-05)]\n",
            "max regret amoung agents tensor(0.0006)\n",
            "social cost  tensor(0.2333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  26 minibatch loss   tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0699, 0.8051, 0.8228, 0.9199, 0.7863], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 43\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 53\n",
            "regret is  [tensor(-0.0012), tensor(1.9261e-05), tensor(-0.0004), tensor(-0.0012), tensor(-0.0024)]\n",
            "max regret amoung agents tensor(1.9261e-05)\n",
            "social cost  tensor(0.2293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  26 minibatch loss   tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.3405, 0.2243, 0.6108, 0.9581, 0.6899], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 46\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 56\n",
            "For agent  4  no of beta matches with peak 42\n",
            "regret is  [tensor(0.0005), tensor(0.0006), tensor(0.0004), tensor(-0.0002), tensor(0.0011)]\n",
            "max regret amoung agents tensor(0.0011)\n",
            "social cost  tensor(0.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  26 minibatch loss   tensor(0.2249, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  26 training loss  tensor(0.2292)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.6468, 0.7067, 0.6176, 0.4891, 0.1013], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 54\n",
            "For agent  1  no of beta matches with peak 49\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 58\n",
            "regret is  [tensor(-0.0008), tensor(7.8056e-06), tensor(-0.0002), tensor(4.7902e-05), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  27 minibatch loss   tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.6118, 0.1178, 0.5975, 0.2292, 0.0933], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 45\n",
            "For agent  2  no of beta matches with peak 58\n",
            "For agent  3  no of beta matches with peak 36\n",
            "For agent  4  no of beta matches with peak 35\n",
            "regret is  [tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0001)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  27 minibatch loss   tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.5465, 0.6388, 0.4091, 0.3904, 0.3381], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 54\n",
            "For agent  1  no of beta matches with peak 46\n",
            "For agent  2  no of beta matches with peak 55\n",
            "For agent  3  no of beta matches with peak 55\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(0.0005), tensor(-5.3275e-06), tensor(0.0002), tensor(0.0003), tensor(9.7089e-05)]\n",
            "max regret amoung agents tensor(0.0005)\n",
            "social cost  tensor(0.2267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  27 minibatch loss   tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  27 training loss  tensor(0.2279)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.4530, 0.0029, 0.0864, 0.2472, 0.5969], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 42\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 56\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(0.0015), tensor(0.0010), tensor(0.0023), tensor(0.0015), tensor(0.0017)]\n",
            "max regret amoung agents tensor(0.0023)\n",
            "social cost  tensor(0.2294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  28 minibatch loss   tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.2161, 0.1510, 0.7835, 0.6446, 0.7731], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 39\n",
            "For agent  2  no of beta matches with peak 64\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(0.0001), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0003)\n",
            "social cost  tensor(0.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  28 minibatch loss   tensor(0.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.5858, 0.5216, 0.0297, 0.6859, 0.1421], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 42\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 48\n",
            "regret is  [tensor(0.0006), tensor(0.0005), tensor(0.0002), tensor(0.0010), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0010)\n",
            "social cost  tensor(0.2270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  28 minibatch loss   tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  28 training loss  tensor(0.2266)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.3842, 0.6223, 0.1756, 0.5571, 0.0191], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 39\n",
            "For agent  3  no of beta matches with peak 43\n",
            "For agent  4  no of beta matches with peak 57\n",
            "regret is  [tensor(0.0010), tensor(0.0008), tensor(0.0012), tensor(0.0008), tensor(0.0004)]\n",
            "max regret amoung agents tensor(0.0012)\n",
            "social cost  tensor(0.2294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  29 minibatch loss   tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.0267, 0.7245, 0.5461, 0.2114, 0.9818], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 46\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 55\n",
            "For agent  3  no of beta matches with peak 52\n",
            "For agent  4  no of beta matches with peak 38\n",
            "regret is  [tensor(0.0010), tensor(0.0010), tensor(0.0008), tensor(0.0016), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0016)\n",
            "social cost  tensor(0.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  29 minibatch loss   tensor(0.2233, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.0049005\n",
            "betas tensor([0.3396, 0.6602, 0.7420, 0.0618, 0.4715], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 57\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 51\n",
            "For agent  4  no of beta matches with peak 65\n",
            "regret is  [tensor(0.0004), tensor(0.0016), tensor(0.0004), tensor(0.0010), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0016)\n",
            "social cost  tensor(0.2211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  29 minibatch loss   tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  29 training loss  tensor(0.2247)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.8250, 0.0590, 0.9218, 0.6759, 0.0240], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 49\n",
            "For agent  3  no of beta matches with peak 52\n",
            "For agent  4  no of beta matches with peak 64\n",
            "regret is  [tensor(0.0002), tensor(0.0008), tensor(0.0006), tensor(0.0003), tensor(0.0010)]\n",
            "max regret amoung agents tensor(0.0010)\n",
            "social cost  tensor(0.2309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  30 minibatch loss   tensor(0.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.3330, 0.3620, 0.8833, 0.4970, 0.6419], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 65\n",
            "For agent  1  no of beta matches with peak 59\n",
            "For agent  2  no of beta matches with peak 70\n",
            "For agent  3  no of beta matches with peak 34\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(0.0008), tensor(0.0009), tensor(0.0001), tensor(0.0006), tensor(-0.0002)]\n",
            "max regret amoung agents tensor(0.0009)\n",
            "social cost  tensor(0.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  30 minibatch loss   tensor(0.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.3221, 0.7681, 0.5141, 0.3040, 0.8571], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 50\n",
            "For agent  1  no of beta matches with peak 53\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 62\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(0.0003), tensor(0.0006), tensor(0.0009), tensor(0.0006), tensor(0.0009)]\n",
            "max regret amoung agents tensor(0.0009)\n",
            "social cost  tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  30 minibatch loss   tensor(0.2196, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  30 training loss  tensor(0.2238)\n",
            " current lambda tensor(0.1000)  to minus  tensor(4.4932e-07)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.1955, 0.5365, 0.5324, 0.4667, 0.2460], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 33\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 34\n",
            "regret is  [tensor(0.0014), tensor(0.0011), tensor(0.0004), tensor(0.0017), tensor(0.0011)]\n",
            "max regret amoung agents tensor(0.0017)\n",
            "social cost  tensor(0.2216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  31 minibatch loss   tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.8527, 0.1281, 0.0091, 0.1100, 0.9844], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 45\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 37\n",
            "For agent  4  no of beta matches with peak 55\n",
            "regret is  [tensor(0.0004), tensor(4.8777e-05), tensor(0.0003), tensor(7.6403e-05), tensor(7.7111e-05)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  31 minibatch loss   tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.0031, 0.1864, 0.0447, 0.1997, 0.6985], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 47\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 36\n",
            "For agent  4  no of beta matches with peak 55\n",
            "regret is  [tensor(0.0004), tensor(-0.0004), tensor(-0.0006), tensor(-0.0010), tensor(-0.0007)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  31 minibatch loss   tensor(0.2213, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  31 training loss  tensor(0.2226)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5176, 0.3802, 0.3225, 0.3721, 0.8272], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 47\n",
            "For agent  1  no of beta matches with peak 41\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 49\n",
            "regret is  [tensor(-3.4618e-05), tensor(-0.0003), tensor(-0.0002), tensor(0.0002), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  32 minibatch loss   tensor(0.2210, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.8233, 0.1076, 0.6132, 0.0489, 0.3659], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 51\n",
            "For agent  3  no of beta matches with peak 36\n",
            "For agent  4  no of beta matches with peak 46\n",
            "regret is  [tensor(0.0006), tensor(0.0002), tensor(1.9710e-05), tensor(0.0004), tensor(-0.0002)]\n",
            "max regret amoung agents tensor(0.0006)\n",
            "social cost  tensor(0.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  32 minibatch loss   tensor(0.2247, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6987, 0.2457, 0.5543, 0.1874, 0.0869], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 40\n",
            "For agent  1  no of beta matches with peak 57\n",
            "For agent  2  no of beta matches with peak 43\n",
            "For agent  3  no of beta matches with peak 50\n",
            "For agent  4  no of beta matches with peak 60\n",
            "regret is  [tensor(0.0005), tensor(0.0009), tensor(0.0015), tensor(0.0009), tensor(0.0012)]\n",
            "max regret amoung agents tensor(0.0015)\n",
            "social cost  tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  32 minibatch loss   tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  32 training loss  tensor(0.2221)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.7303, 0.7920, 0.6089, 0.2512, 0.2019], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 58\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 56\n",
            "For agent  3  no of beta matches with peak 39\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(0.0005), tensor(0.0004), tensor(0.0007), tensor(0.0004), tensor(0.0006)]\n",
            "max regret amoung agents tensor(0.0007)\n",
            "social cost  tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  33 minibatch loss   tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.0108, 0.3965, 0.5066, 0.2095, 0.4252], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 44\n",
            "For agent  4  no of beta matches with peak 54\n",
            "regret is  [tensor(0.0026), tensor(0.0021), tensor(0.0020), tensor(0.0022), tensor(0.0018)]\n",
            "max regret amoung agents tensor(0.0026)\n",
            "social cost  tensor(0.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  33 minibatch loss   tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6396, 0.6351, 0.2966, 0.6214, 0.5433], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 34\n",
            "For agent  1  no of beta matches with peak 34\n",
            "For agent  2  no of beta matches with peak 37\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 38\n",
            "regret is  [tensor(0.0002), tensor(-4.2441e-05), tensor(-0.0004), tensor(0.0002), tensor(-0.0007)]\n",
            "max regret amoung agents tensor(0.0002)\n",
            "social cost  tensor(0.2210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  33 minibatch loss   tensor(0.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  33 training loss  tensor(0.2205)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6319, 0.1524, 0.6646, 0.9280, 0.8035], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 40\n",
            "For agent  1  no of beta matches with peak 58\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 59\n",
            "For agent  4  no of beta matches with peak 48\n",
            "regret is  [tensor(0.0005), tensor(-3.4520e-05), tensor(-0.0004), tensor(0.0005), tensor(0.0004)]\n",
            "max regret amoung agents tensor(0.0005)\n",
            "social cost  tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  34 minibatch loss   tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.8796, 0.7655, 0.0424, 0.9255, 0.4825], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 43\n",
            "For agent  1  no of beta matches with peak 60\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 58\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(0.0005), tensor(-0.0010), tensor(0.0011), tensor(0.0008), tensor(0.0002)]\n",
            "max regret amoung agents tensor(0.0011)\n",
            "social cost  tensor(0.2190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  34 minibatch loss   tensor(0.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5378, 0.7927, 0.8964, 0.4510, 0.8632], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 60\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 55\n",
            "For agent  4  no of beta matches with peak 50\n",
            "regret is  [tensor(0.0007), tensor(0.0004), tensor(0.0004), tensor(0.0007), tensor(0.0009)]\n",
            "max regret amoung agents tensor(0.0009)\n",
            "social cost  tensor(0.2170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  34 minibatch loss   tensor(0.2171, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  34 training loss  tensor(0.2188)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5740, 0.7348, 0.1830, 0.8642, 0.8550], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 50\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 43\n",
            "regret is  [tensor(-0.0008), tensor(-0.0006), tensor(-0.0010), tensor(-0.0005), tensor(-0.0006)]\n",
            "max regret amoung agents tensor(-0.0005)\n",
            "social cost  tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  35 minibatch loss   tensor(0.2201, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.9478, 0.4115, 0.3679, 0.6790, 0.3075], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 46\n",
            "For agent  1  no of beta matches with peak 44\n",
            "For agent  2  no of beta matches with peak 60\n",
            "For agent  3  no of beta matches with peak 41\n",
            "For agent  4  no of beta matches with peak 40\n",
            "regret is  [tensor(-0.0002), tensor(-0.0004), tensor(0.0002), tensor(0.0003), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0008)\n",
            "social cost  tensor(0.2193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  35 minibatch loss   tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6477, 0.1802, 0.2588, 0.5841, 0.8281], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 52\n",
            "For agent  1  no of beta matches with peak 51\n",
            "For agent  2  no of beta matches with peak 53\n",
            "For agent  3  no of beta matches with peak 49\n",
            "For agent  4  no of beta matches with peak 56\n",
            "regret is  [tensor(0.0010), tensor(0.0008), tensor(0.0003), tensor(0.0005), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0010)\n",
            "social cost  tensor(0.2158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  35 minibatch loss   tensor(0.2159, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  35 training loss  tensor(0.2185)\n",
            " current lambda tensor(0.1000)  to minus  tensor(4.9522e-07)\n",
            " _lamdda value  tensor(0.1000)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5615, 0.9142, 0.0800, 0.7784, 0.2073], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 45\n",
            "For agent  1  no of beta matches with peak 38\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 54\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(0.0008), tensor(0.0006), tensor(0.0016), tensor(0.0011), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0016)\n",
            "social cost  tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  36 minibatch loss   tensor(0.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5472, 0.3037, 0.7751, 0.2479, 0.7547], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 46\n",
            "For agent  1  no of beta matches with peak 57\n",
            "For agent  2  no of beta matches with peak 44\n",
            "For agent  3  no of beta matches with peak 61\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(0.0012), tensor(0.0006), tensor(0.0005), tensor(0.0008), tensor(0.0004)]\n",
            "max regret amoung agents tensor(0.0012)\n",
            "social cost  tensor(0.2203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  36 minibatch loss   tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.3449, 0.1647, 0.0574, 0.4455, 0.0915], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 47\n",
            "For agent  3  no of beta matches with peak 45\n",
            "For agent  4  no of beta matches with peak 47\n",
            "regret is  [tensor(0.0019), tensor(0.0024), tensor(0.0017), tensor(0.0012), tensor(0.0016)]\n",
            "max regret amoung agents tensor(0.0024)\n",
            "social cost  tensor(0.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  36 minibatch loss   tensor(0.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  36 training loss  tensor(0.2175)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6723, 0.2722, 0.2785, 0.2704, 0.0213], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 32\n",
            "For agent  1  no of beta matches with peak 32\n",
            "For agent  2  no of beta matches with peak 31\n",
            "For agent  3  no of beta matches with peak 34\n",
            "For agent  4  no of beta matches with peak 46\n",
            "regret is  [tensor(-0.0005), tensor(-0.0006), tensor(-0.0009), tensor(-0.0014), tensor(-0.0011)]\n",
            "max regret amoung agents tensor(-0.0005)\n",
            "social cost  tensor(0.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  37 minibatch loss   tensor(0.2135, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.2908, 0.5443, 0.9060, 0.8136, 0.8422], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 55\n",
            "For agent  2  no of beta matches with peak 45\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(0.0010), tensor(0.0006), tensor(-7.3959e-05), tensor(0.0002), tensor(-0.0002)]\n",
            "max regret amoung agents tensor(0.0010)\n",
            "social cost  tensor(0.2173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  37 minibatch loss   tensor(0.2174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.9516, 0.0679, 0.9001, 0.0322, 0.4982], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 51\n",
            "For agent  1  no of beta matches with peak 42\n",
            "For agent  2  no of beta matches with peak 48\n",
            "For agent  3  no of beta matches with peak 48\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(0.0010), tensor(0.0010), tensor(0.0002), tensor(0.0004), tensor(0.0013)]\n",
            "max regret amoung agents tensor(0.0013)\n",
            "social cost  tensor(0.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  37 minibatch loss   tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  37 training loss  tensor(0.2166)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.9804, 0.4602, 0.1859, 0.0264, 0.4854], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 48\n",
            "For agent  2  no of beta matches with peak 41\n",
            "For agent  3  no of beta matches with peak 47\n",
            "For agent  4  no of beta matches with peak 44\n",
            "regret is  [tensor(-0.0002), tensor(0.0004), tensor(0.0002), tensor(0.0005), tensor(0.0007)]\n",
            "max regret amoung agents tensor(0.0007)\n",
            "social cost  tensor(0.2184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  38 minibatch loss   tensor(0.2185, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5608, 0.9580, 0.8537, 0.6637, 0.6921], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 43\n",
            "For agent  1  no of beta matches with peak 50\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 51\n",
            "regret is  [tensor(0.0024), tensor(0.0027), tensor(0.0015), tensor(0.0031), tensor(0.0025)]\n",
            "max regret amoung agents tensor(0.0031)\n",
            "social cost  tensor(0.2159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  38 minibatch loss   tensor(0.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.8348, 0.1053, 0.8354, 0.0705, 0.4614], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 44\n",
            "For agent  1  no of beta matches with peak 40\n",
            "For agent  2  no of beta matches with peak 46\n",
            "For agent  3  no of beta matches with peak 38\n",
            "For agent  4  no of beta matches with peak 45\n",
            "regret is  [tensor(0.0006), tensor(0.0016), tensor(0.0022), tensor(0.0016), tensor(0.0014)]\n",
            "max regret amoung agents tensor(0.0022)\n",
            "social cost  tensor(0.2146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  38 minibatch loss   tensor(0.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  38 training loss  tensor(0.2165)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.9008, 0.1933, 0.6126, 0.2749, 0.1815], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 48\n",
            "For agent  1  no of beta matches with peak 35\n",
            "For agent  2  no of beta matches with peak 43\n",
            "For agent  3  no of beta matches with peak 46\n",
            "For agent  4  no of beta matches with peak 36\n",
            "regret is  [tensor(0.0004), tensor(-9.8164e-05), tensor(-0.0001), tensor(-0.0006), tensor(-0.0002)]\n",
            "max regret amoung agents tensor(0.0004)\n",
            "social cost  tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  39 minibatch loss   tensor(0.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.5012, 0.1851, 0.2903, 0.2399, 0.5393], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 49\n",
            "For agent  1  no of beta matches with peak 47\n",
            "For agent  2  no of beta matches with peak 54\n",
            "For agent  3  no of beta matches with peak 55\n",
            "For agent  4  no of beta matches with peak 52\n",
            "regret is  [tensor(0.0014), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0014)]\n",
            "max regret amoung agents tensor(0.0014)\n",
            "social cost  tensor(0.2137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  39 minibatch loss   tensor(0.2138, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "current learning rate  0.004851495\n",
            "betas tensor([0.6072, 0.1970, 0.1795, 0.7826, 0.3546], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 55\n",
            "For agent  1  no of beta matches with peak 64\n",
            "For agent  2  no of beta matches with peak 52\n",
            "For agent  3  no of beta matches with peak 57\n",
            "For agent  4  no of beta matches with peak 58\n",
            "regret is  [tensor(0.0004), tensor(0.0012), tensor(0.0003), tensor(0.0005), tensor(0.0003)]\n",
            "max regret amoung agents tensor(0.0012)\n",
            "social cost  tensor(0.2109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch :  39 minibatch loss   tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Epoch :  39 training loss  tensor(0.2154)\n",
            "betas tensor([0.9324, 0.9734, 0.3483, 0.7654, 0.1521], device='cuda:0')\n",
            "For agent  0  no of beta matches with peak 127\n",
            "For agent  1  no of beta matches with peak 151\n",
            "For agent  2  no of beta matches with peak 154\n",
            "For agent  3  no of beta matches with peak 159\n",
            "For agent  4  no of beta matches with peak 155\n",
            "regret is  [tensor(0.0009), tensor(0.0005), tensor(0.0007), tensor(0.0010), tensor(0.0008)]\n",
            "max regret amoung agents tensor(0.0010)\n",
            "social cost  tensor(0.2168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Testing Loss is  tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "max regret is  tensor(0.0010)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXkRJJzJE9Oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}