{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegretNet in pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMiCfCrJ73Rl5M5hIqLtMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shailymishra/Paper-Presentation-Summary-Implementation/blob/main/RegretNet_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGkMNO5XFZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "43c3637f-426e-49e2-9cf4-8c0ccb7f7308"
      },
      "source": [
        "## Imports\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.util.testing as tm\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from torch import nn, optim\n",
        "\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqNlvKVyX7Dg"
      },
      "source": [
        "## Config\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# `pip install easydict` if you don't have it\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "__C = edict()\n",
        "cfg = __C\n",
        "\n",
        "# Output-dir to write log-files and save model\n",
        "__C.dir_name = os.path.join(\"experiments\", \"additive_1x2_uniform\")\n",
        "\n",
        "# Auction params\n",
        "__C.num_agents = 1\n",
        "__C.num_items = 2\n",
        "__C.distribution_type = \"uniform\"\n",
        "__C.agent_type = \"additive\"\n",
        "\n",
        "# Save data for restore.\n",
        "__C.save_data = False\n",
        "\n",
        "# Neural Net parameters\n",
        "__C.net = edict()    \n",
        "# initialization g - glorot, h - he + u - uniform, n - normal [gu, gn, hu, hn]\n",
        "__C.net.init = \"gu\"\n",
        "# activations [\"tanh\", \"sigmoid\", \"relu\"]\n",
        "# num_a_layers, num_p_layers - total number of hidden_layers + output_layer, [a - alloc, p - pay]\n",
        "# num_p_hidden_units, num_p_hidden_units - number of hidden units, [a - alloc, p - pay]\n",
        "__C.net.num_a_layers = 3\n",
        "__C.net.num_a_activation = [\"tanh\", \"tanh\", \"softmax\"]\n",
        "__C.net.num_a_units = [__C.num_items*__C.num_agents, 100,100,__C.num_items*__C.num_agents]\n",
        "__C.net.num_p_layers = 3\n",
        "__C.net.num_p_activation = [\"tanh\", \"tanh\", \"sigmoid\"]\n",
        "__C.net.num_p_units = [__C.num_items*__C.num_agents ,100,100,  __C.num_agents]\n",
        "\n",
        "# Train paramters\n",
        "__C.train = edict()\n",
        "\n",
        "# Random seed\n",
        "__C.train.seed = 42\n",
        "# Iter from which training begins. If restore_iter = 0 for default. restore_iter > 0 for starting\n",
        "# training form restore_iter [needs saved model]\n",
        "__C.train.restore_iter = 0\n",
        "# max iters to train \n",
        "# __C.train.max_iter = 400000  ##CHANGED\n",
        "__C.train.max_iter = 100\n",
        "# Learning rate of network param updates\n",
        "__C.train.learning_rate = 1e-3\n",
        "# Regularization\n",
        "__C.train.wd = None\n",
        "\n",
        "\"\"\" Train-data params \"\"\"\n",
        "# Choose between fixed and online. If online, set adv_reuse to False\n",
        "__C.train.data = \"fixed\"\n",
        "# Number of batches\n",
        "# __C.train.num_batches = 5000  ##CHANGED\n",
        "__C.train.num_batches = 1\n",
        "# Train batch size\n",
        "# __C.train.batch_size = 128 ##CHANGED\n",
        "__C.train.batch_size = 5\n",
        "\n",
        "\n",
        "\"\"\" Train-misreport params \"\"\"\n",
        "# Cache-misreports after misreport optimization\n",
        "__C.train.adv_reuse = True\n",
        "# Number of misreport initialization for training\n",
        "__C.train.num_misreports = 1\n",
        "# Number of steps for misreport computation\n",
        "__C.train.gd_iter = 25\n",
        "# Learning rate of misreport computation\n",
        "__C.train.gd_lr = 0.1\n",
        "\n",
        "\"\"\" Lagrange Optimization params \"\"\"\n",
        "# Initial update rate\n",
        "__C.train.update_rate = 1.0\n",
        "# Initial Lagrange weights\n",
        "__C.train.w_rgt_init_val = 5.0\n",
        "# Lagrange update frequency\n",
        "# __C.train.update_frequency = 100 ##CHANGED\n",
        "__C.train.update_frequency = 10\n",
        "# Value by which update rate is incremented\n",
        "__C.train.up_op_add = 50.0\n",
        "# Frequency at which update rate is incremented\n",
        "__C.train.up_op_frequency = 10000\n",
        "\n",
        "\n",
        "\"\"\" train summary and save params\"\"\"\n",
        "# Number of models to store on disk\n",
        "__C.train.max_to_keep = 25\n",
        "# Frequency at which models are saved-\n",
        "__C.train.save_iter = 20000 \n",
        "# Train stats print frequency\n",
        "# __C.train.print_iter = 1000   ##changed\n",
        "__C.train.print_iter = 10\n",
        "   \n",
        "\n",
        "\"\"\" Validation params \"\"\"\n",
        "__C.val = edict()\n",
        "# Number of steps for misreport computation\n",
        "# __C.val.gd_iter = 2000   ##changed\n",
        "__C.val.gd_iter = 20\n",
        "# Learning rate for misreport computation\n",
        "__C.val.gd_lr = 0.1\n",
        "# Number of validation batches\n",
        "__C.val.num_batches = 20\n",
        "# Frequency at which validation is performed\n",
        "# __C.val.print_iter = 10000   ##changed\n",
        "__C.val.print_iter = 10\n",
        "# Validation data frequency\n",
        "__C.val.data = \"fixed\"\n",
        "\n",
        "\"\"\" Test params \"\"\"\n",
        "# Test set\n",
        "__C.test = edict()\n",
        "# Test Seed\n",
        "__C.test.seed = 100\n",
        "# Model to be evaluated\n",
        "__C.test.restore_iter = 400000\n",
        "# Number of misreports\n",
        "__C.test.num_misreports = 1000\n",
        "# Number of steps for misreport computation\n",
        "__C.test.gd_iter = 2000\n",
        "# Learning rate for misreport computation\n",
        "__C.test.gd_lr = 0.1\n",
        "# Test data\n",
        "__C.test.data = \"online\"\n",
        "# Number of test batches\n",
        "__C.test.num_batches = 100\n",
        "# Test batch size\n",
        "__C.test.batch_size = 100\n",
        "# Save Ouput\n",
        "__C.test.save_output = False\n",
        "\n",
        "\n",
        "# Fixed Val params\n",
        "__C.val.batch_size = __C.train.batch_size\n",
        "__C.val.num_misreports = __C.train.num_misreports\n",
        "\n",
        "# Compute number of samples\n",
        "__C.train.num_instances = __C.train.num_batches * __C.train.batch_size\n",
        "__C.val.num_instances = __C.val.num_batches * __C.val.batch_size\n",
        "__C.test.num_instances = __C.test.num_batches * __C.test.batch_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOpfDfJnXvY_"
      },
      "source": [
        "## Create Data\n",
        "\n",
        "## data n_samples x n_agents x n_items\n",
        "## n_samples x 1 x 2\n",
        "\n",
        "def generate_random_X(shape):\n",
        "  return np.random.rand(*shape)\n",
        "\n",
        "def generate_random_ADV(shape):\n",
        "    return np.random.rand(*shape)\n",
        "\n",
        "def preprocessdata(data):\n",
        "  return torch.squeeze(data,1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfxLMceXXx5Z"
      },
      "source": [
        "## Create Net\n",
        "\n",
        "class RegretNet(nn.Module):\n",
        "    def __init__(self,  config):\n",
        "        super(RegretNet, self).__init__()\n",
        "        self.num_items = config.num_items\n",
        "        self.num_agents = config.num_agents\n",
        "        self.num_a_units = config.net.num_a_units\n",
        "        self.num_a_layers = config.net.num_a_layers\n",
        "        self.num_a_activation =  config.net.num_a_activation\n",
        "        self.num_p_units = config.net.num_p_units\n",
        "        self.num_p_layers = config.net.num_p_layers\n",
        "        self.num_p_activation =  config.net.num_p_activation\n",
        "        self.num_misreports = config.train.num_misreports\n",
        "        \n",
        "        # self.u_shape = [self.num_agents, config.train.num_misreports, config.train.batch_size, self.num_agents]\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.update_rate = config.train.update_rate\n",
        "\n",
        "        self.w_rgt_init_val =  config.train.w_rgt_init_val\n",
        "\n",
        "        self.w_rgt = np.ones(self.num_agents).astype(np.float32) * self.w_rgt_init_val\n",
        "        self.w_rgt  = torch.tensor(self.w_rgt)\n",
        "\n",
        "        print('   w_rgt  ', self.w_rgt)\n",
        "\n",
        "\n",
        "        self.activation = {'sigmoid': nn.Sigmoid() , 'tanh' : nn.Tanh() , 'softmax' : nn.Softmax()  }\n",
        "        \n",
        "        ## Layers\n",
        "        self.allocationNetwork = nn.ModuleList([ nn.Linear(  self.num_a_units[i] , self.num_a_units[i+1]  )   for i in range(self.num_a_layers)])\n",
        "        self.paymentNetwork = nn.ModuleList([ nn.Linear(  self.num_p_units[i] , self.num_p_units[i+1]  )   for i in range(self.num_p_layers)])\n",
        "        \n",
        "        for i in range(self.num_a_layers) : \n",
        "          torch.nn.init.xavier_uniform(self.allocationNetwork[i].weight) \n",
        "          self.allocationNetwork[i].bias.data.fill_(0.00) \n",
        "        for i in range(self.num_p_layers) :\n",
        "          torch.nn.init.xavier_uniform(self.paymentNetwork[i].weight)\n",
        "          self.paymentNetwork[i].bias.data.fill_(0.00) \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      allocation = x\n",
        "      payment = x\n",
        "      for i in range(self.num_a_layers):\n",
        "        allocation = self.allocationNetwork[i](allocation)\n",
        "        allocation =  self.activation[self.num_a_activation[i]](allocation)\n",
        "      \n",
        "      for i in range(self.num_p_layers):\n",
        "        payment = self.paymentNetwork[i](payment)\n",
        "        payment =  self.activation[self.num_p_activation[i]](payment)\n",
        "\n",
        "      n_samples = allocation.shape[0]\n",
        "      allocXval = torch.reshape(allocation * x, (n_samples,  self.num_agents ,self.num_items  ))\n",
        "      payment = payment *  torch.sum( allocXval, dim=2)  ## summing for each agent, over all items\n",
        "      return allocation , payment\n",
        "\n",
        "    def compute_rev(self, payment):\n",
        "      return torch.mean(torch.sum(payment, dim=1))\n",
        "\n",
        "    def compute_utility(self, x, allocation, payment):\n",
        "      n_samples = x.shape[0]\n",
        "      # x = x.reshape(n_samples, self.num_agents , self.num_items)\n",
        "      allocXval = torch.reshape(allocation * x, (n_samples,  self.num_agents , self.num_items  ))\n",
        "\n",
        "      utility = torch.sum( allocXval, dim=2) - payment\n",
        "      return utility\n",
        "    \n",
        "    def compute_regret(self,x, misreports, utility_true):\n",
        "      n_samples = misreports.shape[1]\n",
        "      misreports_allocation = []\n",
        "      misreports_payments = []\n",
        "      for i in range(self.num_misreports):\n",
        "        a , p = net.forward(preprocessdata(misreports[i]))\n",
        "        misreports_allocation.append(a)\n",
        "        misreports_payments.append(p)\n",
        "      misreports_allocation = torch.stack(misreports_allocation)\n",
        "      misreports_payments = torch.stack(misreports_payments)\n",
        "      \n",
        "      misreports_utility = [ net.compute_utility(x, misreports_allocation[i],  misreports_payments[i] ) for i in range(self.num_misreports)]\n",
        "      misreports_utility = torch.stack(misreports_utility)\n",
        "\n",
        "      difference = self.relu(misreports_utility - utility_true)\n",
        "      maxdifference , indices= torch.max(difference , dim=0)\n",
        "      regret = torch.mean(maxdifference, dim=1)\n",
        "      return  regret , misreports_utility\n",
        "\n",
        "    def loss_function(self, allocation, payment , train_data , train_misreports_data ):\n",
        "      revenue = self.compute_rev(payment)\n",
        "      utility = self.compute_utility(train_data, allocation, payment)\n",
        "      regret , misreports_utility = self.compute_regret(train_data, train_misreports_data , utility)\n",
        "\n",
        "      print(' revenue is ', revenue)\n",
        "\n",
        "      rgt_mean = torch.mean(regret) \n",
        "      irp_mean = torch.mean(self.relu(-utility))\n",
        "      rgt_penalty = self.update_rate * torch.sum(torch.square(regret)) / 2.0 \n",
        "      \n",
        "      lag_loss = torch.sum(self.w_rgt * regret)\n",
        "        \n",
        "      loss_1 = -revenue + rgt_penalty + lag_loss\n",
        "      loss_2 = -torch.sum(misreports_utility)\n",
        "      loss_3 = -lag_loss\n",
        "\n",
        "            #       reg_losses = tf.get_collection('reg_losses')\n",
        "            # if len(reg_losses) > 0:\n",
        "            #     reg_loss_mean = tf.reduce_mean(reg_losses)\n",
        "            #     loss_1 = loss_1 + reg_loss_mean\n",
        "\n",
        "      self.metrics = [revenue, rgt_mean, rgt_penalty, lag_loss, loss_1, torch.mean(self.w_rgt), self.update_rate]\n",
        "      self.metric_names = [\"Revenue\", \"Regret\", \"Reg_Loss\", \"Lag_Loss\", \"Net_Loss\", \"w_rgt_mean\", \"update_rate\"]\n",
        "\n",
        "\n",
        "      return  loss_1 , loss_2 , loss_3 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnqTxwoXy7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee4fac21-b385-4fb9-c5e0-da1c85fcfded"
      },
      "source": [
        "## Create train , val , test\n",
        "\n",
        "\n",
        "np.random.seed(cfg.train.seed)\n",
        "net = RegretNet(cfg)\n",
        "\n",
        "train_data_shape = [cfg.train.num_instances , cfg.num_agents, cfg.num_items]\n",
        "train_adv_shape = [cfg.train.num_misreports, cfg.train.num_instances, cfg.num_agents, cfg.num_items]\n",
        "\n",
        "train_data = generate_random_X(train_data_shape)\n",
        "train_data = torch.from_numpy(train_data).float()\n",
        "train_data = preprocessdata(train_data)\n",
        "\n",
        "train_misreports_data = generate_random_ADV(train_adv_shape)\n",
        "train_misreports_data = torch.from_numpy(train_misreports_data).float()\n",
        "\n",
        "# temp =  [train_misreports_data]\n",
        "temp = [torch.tensor(train_misreports_data,requires_grad=True  )]\n",
        "optimizer_1  = optim.Adam(net.parameters(), cfg.train.learning_rate)\n",
        "optimizer_2 = optim.Adam(temp, lr =  cfg.train.gd_lr )\n",
        "\n",
        "\n",
        "allocation , payment  = net(train_data)\n",
        "\n",
        "loss1, loss2,loss3 = net.loss_function(allocation, payment ,  train_data,  train_misreports_data)\n",
        "\n",
        "print(' Update for Misreports')            \n",
        "for _ in range(cfg.train.gd_iter):\n",
        "  print(_)\n",
        "  optimizer_2.zero_grad()\n",
        "  loss1, loss2,loss3 = net.loss_function(allocation, payment ,  train_data,  temp[0])\n",
        "  loss2.backward()\n",
        "  optimizer_2.step()\n",
        "  temp[0].data.clamp_(0,1)\n",
        "  print()\n",
        "  print(temp)\n",
        "  print()\n",
        "\n",
        "print('___________________________________________________')\n",
        "for i in range(len(net.metric_names)):\n",
        "  print( net.metric_names[i] , ' : ' , net.metrics[i] )\n",
        "print('___________________________________________________')\n",
        "\n",
        "\n",
        "# optimizer_1.zero_grad()\n",
        "# loss1.backward()\n",
        "# optimizer_1.step()\n",
        "# allocation , payment  = net(train_data)\n",
        "\n",
        "\n",
        "# optimizer.zero_grad()\n",
        "#     output = model(input)\n",
        "#     loss = loss_fn(output, target)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "\n",
        "# loss1, loss2,loss3 = net.loss_function(allocation, payment ,  train_data,  train_misreports_data)\n",
        "# optimizer_1.zero_grad()\n",
        "# loss1.backward()\n",
        "# r = optimizer_1.step()\n",
        "# print(' loss 1 ', loss1 , ' loss 2 ', loss2 , ' loss 3 ', loss3)\n",
        "\n",
        "# print('________________________')\n",
        "# print(train_misreports_data)\n",
        "# print('________________________')\n",
        "\n",
        "  \n",
        "\n",
        "            # Optimizer\n",
        "\n",
        "\n",
        "# print('___________________________________________________')\n",
        "# for i in range(len(net.metric_names)):\n",
        "#   print( net.metric_names[i] , ' : ' , net.metrics[i] )\n",
        "# print('___________________________________________________')\n",
        "\n",
        "# revenue = net.compute_rev(payment)\n",
        "# utility = net.compute_utility(train_data, allocation, payment)\n",
        "\n",
        "# regret = net.compute_regret(train_misreports_data , utility)\n",
        "\n",
        "\n",
        "\n",
        "### update loss and check if that is also fine\n",
        "### then for on batches\n",
        "### then save model , and \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   w_rgt   tensor([5.])\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            " Update for Misreports\n",
            "0\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.8699]],\n",
            "\n",
            "         [[0.7324, 0.1123]],\n",
            "\n",
            "         [[0.0818, 0.0834]],\n",
            "\n",
            "         [[0.2042, 0.4248]],\n",
            "\n",
            "         [[0.3319, 0.1912]]]], requires_grad=True)]\n",
            "\n",
            "1\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.7699]],\n",
            "\n",
            "         [[0.6324, 0.0123]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.1042, 0.3247]],\n",
            "\n",
            "         [[0.2319, 0.0912]]]], requires_grad=True)]\n",
            "\n",
            "2\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.6698]],\n",
            "\n",
            "         [[0.5324, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0042, 0.2246]],\n",
            "\n",
            "         [[0.1320, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "3\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.5695]],\n",
            "\n",
            "         [[0.4324, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.1245]],\n",
            "\n",
            "         [[0.0320, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "4\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.4692]],\n",
            "\n",
            "         [[0.3324, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0242]],\n",
            "\n",
            "         [[0.0000, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "5\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.3687]],\n",
            "\n",
            "         [[0.2323, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "6\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.2680]],\n",
            "\n",
            "         [[0.1322, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "7\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.1671]],\n",
            "\n",
            "         [[0.0321, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "8\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0.0000, 0.0660]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000]]]], requires_grad=True)]\n",
            "\n",
            "9\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "10\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "11\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "12\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "13\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "14\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "15\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "16\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "17\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "18\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "19\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "20\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "21\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "22\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "23\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "24\n",
            " revenue is  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "\n",
            "[tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]], requires_grad=True)]\n",
            "\n",
            "___________________________________________________\n",
            "Revenue  :  tensor(0.2515, grad_fn=<MeanBackward0>)\n",
            "Regret  :  tensor(0.2654, grad_fn=<MeanBackward0>)\n",
            "Reg_Loss  :  tensor(0.2006, grad_fn=<DivBackward0>)\n",
            "Lag_Loss  :  tensor(6.6348, grad_fn=<SumBackward0>)\n",
            "Net_Loss  :  tensor(6.5840, grad_fn=<AddBackward0>)\n",
            "w_rgt_mean  :  tensor(5.)\n",
            "update_rate  :  1.0\n",
            "___________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfMG8ECDcngm"
      },
      "source": [
        "n_samples = 2\n",
        "n_items = 2\n",
        "n_agents = 3\n",
        "allocation = torch.tensor([[0.4 , 0.2 , 0.5 , 0.6, 0.7,0.4 ], [0.1 , 0.3 , 0.7 , 0.2,0.1,0.2 ] ])\n",
        "valuation = torch.tensor([[0.1 , 0.2 , 0.5 , 0.3 , 0.8,0.6], [0.54 , 0.2 , 0.7 , 0.8, 0.8,0.9 ] ])\n",
        "\n",
        "payment = torch.tensor([[0.13 , 0.33, 0.6], [0.76, 0.65, 0.6]])\n",
        "allocXval = torch.reshape(allocation * valuation, (n_samples,  n_agents , n_items  ))\n",
        "# payment = payment *  torch.sum( allocXval, dim=2)\n",
        "utility =  torch.sum( allocXval, dim=2) - payment\n",
        "\n",
        "print('________________________________________________________________')\n",
        "print(utility)\n",
        "print('________________________________________________________________')\n",
        "\n",
        "v_misreports = torch.tensor([ [[0.3 , 0.24 , 0.25 , 0.38 , 0.38,0.16], [0.5 , 0.12 , 0.47 , 0.28, 0.81,0.5 ] ],\n",
        "                           [[0.5 , 0.25 , 0.25 , 0.73 , 0.877,0.61], [0.4 , 0.22 , 0.37 , 0.38, 0.5,0.3 ] ]\n",
        "])\n",
        "\n",
        "a_misreports = torch.tensor([ [[0.3 , 0.24 , 0.25 , 0.38 , 0.38,0.16], [0.5 , 0.12 , 0.47 , 0.28, 0.81,0.5 ] ],\n",
        "                           [[0.5 , 0.25 , 0.25 , 0.73 , 0.877,0.61], [0.4 , 0.22 , 0.37 , 0.38, 0.5,0.3 ] ]\n",
        "])\n",
        "\n",
        "p_misreports = torch.tensor([ [[0.7 , 0.7 , 0.7  ], [0.5 , 0.12 , 0.47 , ] ],\n",
        "                           [[0.5 , 0.25 , 0.25], [0.4 , 0.22 , 0.37  ] ]\n",
        "])\n",
        "\n",
        "n_misreports = 2\n",
        "\n",
        "allocXvalu_misreports = torch.reshape(a_misreports * v_misreports, (n_misreports, n_samples,  n_agents , n_items  ))\n",
        "u_misreports =  torch.sum( allocXvalu_misreports, dim=3) - p_misreports\n",
        "print('________________________________________________________________')\n",
        "print(u_misreports)\n",
        "print('________________________________________________________________')\n",
        "\n",
        "\n",
        "relu = nn.ReLU()\n",
        "difference = relu(u_misreports - utility)\n",
        "print('________________________________________________________________')\n",
        "print(difference)\n",
        "print('________________________________________________________________')\n",
        "\n",
        "maxdiff , indices= torch.max(difference , dim=0)\n",
        "print('________________________________________________________________')\n",
        "print(maxdiff)\n",
        "print('________________________________________________________________')\n",
        "\n",
        "regret = torch.mean(maxdiff, dim=1)\n",
        "print('________________________________________________________________')\n",
        "print(regret)\n",
        "print('________________________________________________________________')\n",
        "\n",
        "\n",
        "# utility2 = [ net.compute_utility(v_misreports[i], a_misreports[i],  p_misreports[i] ) for i in range(n_misreports)]\n",
        "# print('________________________________________________________________')\n",
        "# utility2 = torch.stack(utility2)\n",
        "# print(utility2)\n",
        "# print('________________________________________________________________')\n",
        "\n",
        "\n",
        "# print(misreports.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print('payment')\n",
        "# print(payment)\n",
        "# print('__________________________________________')\n",
        "# print(' Revenue ', torch.mean(torch.sum(payment, dim=1)))\n",
        "# print('__________________________________________')\n",
        "# utility =  torch.sum( allocXval, dim=2) - payment\n",
        "# print('__________________________________________')\n",
        "# print(utility)\n",
        "# print('__________________________________________')\n",
        "\n",
        "\n",
        "# print('allocation')\n",
        "# print(allocation)\n",
        "# print('__________________________________________')\n",
        "\n",
        "# print('valuation')\n",
        "# print(valuation)\n",
        "# print('__________________________________________')\n",
        "\n",
        "# print('__________________________________________')\n",
        "# print(torch.sum(allocXval, dim=2))\n",
        "# print('__________________________________________')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TjGgt0Aeoko"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYrNpA2ADLdv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}